# CHETGPT: Kinda works... but results are not very accurate.

# CHATGPT

## ğŸµ Overview
SONIX ANALYSIS V1A is an advanced **audio analysis and classification tool** that processes audio files to extract **musical, acoustic, and textual features**. It integrates multiple machine learning techniques, audio processing methods, and natural language processing (NLP) tools to analyze **music, speech, and textual content** from audio files.

## ğŸš€ Features
- **ğŸ§ Audio Feature Extraction**: Analyzes energy, tempo, pitch, loudness, and spectral characteristics.
- **ğŸ“ Transcription & NLP**: Converts speech to text and applies sentiment analysis, named entity recognition, and summarization.
- **ğŸ”Š Music Genre Classification**: Uses **fuzzy logic-based classification** to determine probable music genres.
- **ğŸ“Š Acoustic Properties Analysis**: Measures **acousticness, danceability, loudness, instrumentalness, and valence**.
- **ğŸ›ï¸ Audio Processing**: Separates vocals and accompaniment using Spleeter and extracts harmonic/percussive features.
- **ğŸ” Spotify API Integration**: Matches extracted audio features with **Spotify's track recommendation system**.
- **ğŸ“‚ Data Export**: Stores processed insights into an Excel-based **Sonic Analysis Database**.

## ğŸ“¦ Dependencies
Ensure you have the following Python packages installed:
```bash
pip install numpy pandas librosa nltk speechrecognition spotipy requests networkx scipy pywt openai
```

## ğŸ›  How to Use
1. **Prepare Your Audio Files**: Place `.wav` or `.mp3` files in the designated folder.
2. **Run the Script**:
   ```bash
   python SONIX_ANALYSIS_V1A.py
   ```
3. **Follow the Interactive Labeling Process**: Assign metadata to each file (genre, artist, language, etc.).
4. **View Results**: The processed data is stored in `Sonic Analysis Database.xlsx`.

## ğŸ¯ Key Functionalities
### ğŸ¤ **Speech-to-Text & NLP**
- **Transcribes Speech** using Google Web Speech API
- **Named Entity Recognition (NER)** to extract key topics
- **Sentiment Analysis** with Vader Lexicon
- **Summarization** using token-based frequency scoring

### ğŸ¼ **Music Feature Extraction**
- **Tempo & Rhythm Detection**
- **Harmonic vs Percussive Signal Separation**
- **Spectral Analysis & Frequency Mapping**
- **Energy & Loudness Classification**

### ğŸ¶ **Music Genre Classification (Fuzzy Logic)**
- Uses **tempo, energy, loudness, and danceability** to assign probabilities for various music genres
- Aligns extracted insights with **Spotify genre mapping**

### ğŸµ **Spotify API Integration**
- Extracts **Spotify track features** (acousticness, valence, tempo, etc.)
- Recommends similar tracks based on analyzed features

## ğŸ“ File Outputs
- **`Sonic Analysis Database.xlsx`** â†’ Stores all extracted insights and labeled metadata
- **`transcription.txt`** â†’ Stores text transcriptions of speech-containing files
- **`storyboard.jpg`** â†’ Visual representation of detected video scenes (if applicable)

## ğŸ“Œ Next Steps
- Enhance accuracy of **fuzzy genre classification**
- Improve **voice and instrument separation techniques**
- Expand Spotify API integration for **playlist generation**

## ğŸ¤ Contributing
Feel free to contribute by submitting issues or pull requests to improve the feature set!

---
ğŸµ *Bringing AI-powered analysis to music and audio processing!*
